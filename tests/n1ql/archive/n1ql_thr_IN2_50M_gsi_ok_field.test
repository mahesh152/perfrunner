[test_case]
test = perfrunner.tests.n1ql.N1QLThroughputTest
title = IN2 1Bux50Mx1K, Range Insert, 14.4KGops, 3.6KSops, GSI, not_bounded
summary = Key-Value Lookup, 14.4KGops, 3.6KSops
larger_is_better = false

[cluster]
mem_quota = 40960
index_mem_quota = 100000
initial_nodes = 6
num_buckets = 1

[bucket]
replica_number = 1
password =
eviction_policy = valueOnly

[load]
items = 50000000
size = 1024
workers = 20
doc_gen = reverse_lookup
doc_partitions = 1

[n1ql]
indexes =
    by_capped_small::CREATE INDEX {name} ON `{bucket}` (capped_small) using gsi;

[access]
creates = 0
reads = 80
updates = 20
deletes = 0
throughput = 18000
items = 50000000
workers = 24
time = 1200
n1ql_op = rangedelete
n1ql_queries = rangeinsert
n1ql_throughput = 1000000
n1ql_workers = 96

[n1ql-rangeinsert]
prepared = rangeinsert
statement = INSERT INTO `bucket-2` (KEY doc_id, VALUE doc_val) SELECT meta(`bucket-1`).id AS doc_id, name as doc_val FROM `bucket-1` WHERE capped_small = $1;
scan_consistency = not_bounded
args = ["{capped_small}"]
